{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065ce0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "\n",
    "# Beautifulsoup is a class from bs4 library used to parse HTML and XML documents and extract informations from them.\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#Simplifies the process of sending HTTP requests and handling the associated responses.\n",
    "import requests\n",
    "\n",
    "#Provides classes for working with date and time\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "#This module is part of the standard library and provides classes for sending emails using the Simple Mail Transfer Protocol (SMTP).\n",
    "import smtplib\n",
    "\n",
    "## data manipulation library:\n",
    "import pandas as pd\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a67d4fd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Connect to the website\n",
    "\n",
    "url = 'https://www.amazon.es/lenguaje-programaci%C3%B3n-Python-principio-fin/dp/B0B5Q283BL/ref=sr_1_5?__mk_es_ES=%C3%85M%C3%85%C5%BD%C3%95%C3%91&crid=198J5VCRXBMSA&keywords=python&qid=1702808523&sprefix=pytho%2Caps%2C123&sr=8-5'\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"}\n",
    "\n",
    "page = requests.get(url,headers=headers)\n",
    "\n",
    "#pulling content from the webpage\n",
    "soup1 = BeautifulSoup(page.content,\"html.parser\")\n",
    "soup2 = BeautifulSoup(soup1.prettify(),\"html.parser\")\n",
    "\n",
    "print(soup2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7d5d2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Find the element with the 'productTitle' id, get its text content, and remove leading/trailing whitespaces\n",
    "title = soup2.find(id='productTitle').get_text(strip=True)\n",
    "print(title)\n",
    "\n",
    "# Find the element with the 'price' id, get its text content, and remove leading/trailing whitespaces\n",
    "price = soup2.find(id='price').get_text(strip=True)\n",
    "print(price)\n",
    "\n",
    "# Find the element with the 'averageCustomerReviews' id, get its text content, and take the first three characters\n",
    "rate = soup2.find(id='averageCustomerReviews').get_text(strip=True)[:3]\n",
    "print(rate)\n",
    "\n",
    "# Find all images in the document\n",
    "images = soup2.find_all('img')\n",
    "\n",
    "# Replace with the alt text you want to match\n",
    "desired_alt_text = 'El lenguaje de programación Python de principio a fin'\n",
    "\n",
    "# Iterate through the images and print details for the one with the desired alt text\n",
    "for image in images:\n",
    "    name = image.get('alt', '')\n",
    "    link = image.get('src', '')\n",
    "\n",
    "    if name.lower() == desired_alt_text.lower():\n",
    "        print(name, link)\n",
    "        break  # Stop the loop once the desired image is found\n",
    "\n",
    "# Find the element with the 'bookDescription_feature_div' id, get its text content, and remove leading/trailing whitespaces\n",
    "description = soup2.find(id='bookDescription_feature_div').get_text(strip=True)\n",
    "print(description)\n",
    "\n",
    "# Find the parent div with the 'detailBullets_feature_div' id\n",
    "product_details = soup2.find('div', id='detailBullets_feature_div')\n",
    "\n",
    "# Check if product_details exists\n",
    "if product_details:\n",
    "    # Find all span elements with the specified class within the parent div\n",
    "    details = product_details.find_all('span', class_='a-list-item')\n",
    "    \n",
    "    # Iterate through the list under product details and print each element\n",
    "    for data_element in details:\n",
    "        text_content = data_element.get_text(strip=True)\n",
    "        print(text_content)\n",
    "\n",
    "# Find all li elements with the specified class within the document\n",
    "relatedproduct = soup2.find_all('li', class_='a-carousel-card')\n",
    "\n",
    "# Iterate through the list of related products\n",
    "for carousel in relatedproduct:\n",
    "    # Find the <a> tag within the current <li> element\n",
    "    anchor_tag = carousel.find('a')\n",
    "\n",
    "    # Check if an <a> tag is found\n",
    "    if anchor_tag:\n",
    "        # Extract and print the href attribute\n",
    "        href_link = anchor_tag.get('href')\n",
    "        print(f\"Product: {carousel.get_text(strip=True)}, Href: {href_link}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a221121a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a Timestamp for your output to track when data was collected\n",
    "\n",
    "import datetime\n",
    "\n",
    "today = datetime.date.today()\n",
    "\n",
    "print(today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dd22d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#putting everything together\n",
    "# Extracted data\n",
    "title = soup2.find(id='productTitle').get_text(strip=True)\n",
    "price = soup2.find(id='price').get_text(strip=True)\n",
    "rate = soup2.find(id='averageCustomerReviews').get_text(strip=True)[:3]\n",
    "\n",
    "images = soup2.find_all('img')\n",
    "desired_alt_text = 'El lenguaje de programación Python de principio a fin'\n",
    "image_link = None\n",
    "\n",
    "for image in images:\n",
    "    name = image.get('alt', '')\n",
    "    link = image.get('src', '')\n",
    "\n",
    "    if name.lower() == desired_alt_text.lower():\n",
    "        image_link = link\n",
    "        break\n",
    "\n",
    "description = soup2.find(id='bookDescription_feature_div').get_text(strip=True)\n",
    "\n",
    "product_details = soup2.find('div', id='detailBullets_feature_div')\n",
    "details = [data_element.get_text(strip=True) for data_element in product_details.find_all('span', class_='a-list-item')]\n",
    "\n",
    "related_products = []\n",
    "relatedproduct = soup2.find_all('li', class_='a-carousel-card')\n",
    "for carousel in relatedproduct:\n",
    "    anchor_tag = carousel.find('a')\n",
    "    if anchor_tag:\n",
    "        href_link = anchor_tag.get('href')\n",
    "        related_products.append({\"Product\": carousel.get_text(strip=True), \"Href\": href_link})\n",
    "\n",
    "# Create a Timestamp for your output to track when data was collected\n",
    "today = datetime.date.today()\n",
    "\n",
    "#Create a Json file\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "# Your existing code for extracting data\n",
    "\n",
    "# Create a dictionary to store the extracted data\n",
    "data = {\n",
    "    \"title\": title,\n",
    "    \"price\": price,\n",
    "    \"rate\": rate,\n",
    "    \"description\": description,\n",
    "    \"image_link\": image_link,\n",
    "    \"details\": details,\n",
    "    \"related_products\": related_products,\n",
    "    \"timestamp\": str(today),\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a JSON string\n",
    "json_data = json.dumps(data, indent=2)\n",
    "\n",
    "# Save the JSON data to a file\n",
    "output_file_path = \"AmazonScrapping.json\"\n",
    "with open(output_file_path, \"w\") as json_file:\n",
    "    json_file.write(json_data)\n",
    "\n",
    "print(f\"Data saved to {output_file_path}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379d0dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs check_price after a set time and inputs data into your CSV\n",
    "\n",
    "while(True):\n",
    "    check_price()\n",
    "    time.sleep(86400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db709f98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b309b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If uou want to try sending yourself an email (just for fun) when a price hits below a certain level you can try it\n",
    "# out with this script\n",
    "\n",
    "def send_mail():\n",
    "    server = smtplib.SMTP_SSL('smtp.gmail.com',465)\n",
    "    server.ehlo()\n",
    "    #server.starttls()\n",
    "    server.ehlo()\n",
    "    server.login('seifhannachi57@gmail.com','xxxxxxxxxxxxxx')\n",
    "    \n",
    "    subject = \"The book you want is below $15! Now is your chance to buy!\"\n",
    "    body = \"Seif, This is the moment we have been waiting for. Now is your chance to pick up the book of your dreams. Don't mess it up! Link here: https://www.amazon.es/lenguaje-programaci%C3%B3n-Python-principio-fin/dp/B0B5Q283BL/ref=sr_1_5?__mk_es_ES=%C3%85M%C3%85%C5%BD%C3%95%C3%91&crid=198J5VCRXBMSA&keywords=python&qid=1702808523&sprefix=pytho%2Caps%2C123&sr=8-5\"\n",
    "   \n",
    "    msg = f\"Subject: {subject}\\n\\n{body}\"\n",
    "    \n",
    "    server.sendmail(\n",
    "        'seifhannachi57@gmail.com',\n",
    "        msg\n",
    "     \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d22876",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
